{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with `doctest`\n",
    "\n",
    "Why do I maintain the habit of adding a 1 level header? Isn't it unnecessary, since notebooks themselves have a title?\n",
    "\n",
    "Anyway...\n",
    "\n",
    "Idly browsing [The Python Tutorial](https://docs.python.org/3/tutorial/index.html), and particularly it's [10. Brief Tour of the Standard Library](https://docs.python.org/3/tutorial/stdlib.html), I came across `doctest`, introduced in [10.11 Quality Control](https://docs.python.org/3/tutorial/stdlib.html#quality-control), together with `unittest` module which I am familiar with.\n",
    "\n",
    "Doctest is cool, the idea is to use documentation as test. Like so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import doctest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Module doctest -- a framework for running examples in docstrings.\n",
      "\n",
      "In simplest use, end each module M to be tested with:\n",
      "\n",
      "def _test():\n",
      "    import doctest\n",
      "    doctest.testmod()\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    _test()\n",
      "\n",
      "Then running the module as a script will cause the examples in the\n",
      "docstrings to get executed and verified:\n",
      "\n",
      "python M.py\n",
      "\n",
      "This won't display anything unless an example fails, in which case the\n",
      "failing example(s) and the cause(s) of the failure(s) are printed to stdout\n",
      "(why not stderr? because stderr is a lame hack <0.2 wink>), and the final\n",
      "line of output is \"Test failed.\".\n",
      "\n",
      "Run it with the -v switch instead:\n",
      "\n",
      "python M.py -v\n",
      "\n",
      "and a detailed report of all examples tried is printed to stdout, along\n",
      "with assorted summaries at the end.\n",
      "\n",
      "You can force verbose mode by passing \"verbose=True\" to testmod, or prohibit\n",
      "it by passing \"verbose=False\".  In either of those cases, sys.argv is not\n",
      "examined by testmod.\n",
      "\n",
      "There are a variety of other ways to run doctests, including integration\n",
      "with the unittest framework, and support for running non-Python text\n",
      "files containing doctests.  There are also many ways to override parts\n",
      "of doctest's default behaviors.  See the Library Reference Manual for\n",
      "details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(doctest.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(values):\n",
    "    \"\"\"Computes the arithmetic mean of a list of numbers.\n",
    "    \n",
    "    >>> print(average([20, 30, 70]))\n",
    "    40.0\n",
    "    \"\"\"\n",
    "    return sum(values) / len(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I like this stuff, because it keeps documentation, testing and code close. The way to think about it is testing of examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verbosity\n",
    "\n",
    "Verbosity can be added with `verbose=True` to `doctest.testmod()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    print(average([20, 30, 70]))\n",
      "Expecting:\n",
      "    40.0\n",
      "ok\n",
      "1 items had no tests:\n",
      "    __main__\n",
      "1 items passed all tests:\n",
      "   1 tests in __main__.average\n",
      "1 tests in 2 items.\n",
      "1 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `doctest` documentation\n",
    "\n",
    "The [module documentation](https://docs.python.org/3/library/doctest.html#module-doctest) is worth reading of course. Test can also come from a text file, via `doctest.testfile()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animal:\n",
    "    \"\"\"An animal.\n",
    "    \n",
    "    >>> a = Animal(12, \"moo\", [\"grass mostly\"])\n",
    "    >>> a.hp\n",
    "    12\n",
    "    \"\"\"\n",
    "    def __init__(self, hp, sound, diet):\n",
    "        self.sound = sound\n",
    "        self.diet = diet\n",
    "        self.hp = hp\n",
    "\n",
    "    def damage(self, d):\n",
    "        self.hp -= d\n",
    "        print(self.sound)\n",
    "\n",
    "        \n",
    "class Rodent(Animal):\n",
    "    def __init__(self, hp, sound, diet):\n",
    "        super().__init__(hp, sound, diet)\n",
    "        self.hp = hp\n",
    "\n",
    "\n",
    "class Snakie(Animal):\n",
    "    def __init__(self, hp, sound, diet, venomous=False):\n",
    "        super().__init__(hp, sound, diet)\n",
    "        self.sound = sound\n",
    "        self.venomous = venomous\n",
    "        \n",
    "    def bite(self, victim):\n",
    "        \"\"\"Attack a victim and inflict damage.\n",
    "        \n",
    "        >>> r = Rodent(4, 'squeeeek', ['cheese', 'root'])\n",
    "        >>> s = Snakie(5, 'hiss', (Rodent))\n",
    "        >>> s.bite(r)\n",
    "        squeeeek\n",
    "        \n",
    "        >>> r2 = Rodent(4, 'squeak squeak', ['nuts'])\n",
    "        >>> r2.hp\n",
    "        4\n",
    "        \n",
    "        >>> a = Animal(12, \"moo\", [\"grass mostly\"])\n",
    "        >>> s.bite(a)\n",
    "        Not eating <class '__main__.Animal'>\n",
    "        \"\"\"\n",
    "        assert isinstance(victim, Animal)\n",
    "        try:\n",
    "            assert isinstance(victim, self.diet)\n",
    "            victim.damage(2)\n",
    "            if self.venomous:\n",
    "                victim.damage(1)\n",
    "        except AssertionError:\n",
    "            print(\"Not eating {}\".format(type(victim)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squeek\n"
     ]
    }
   ],
   "source": [
    "r = Rodent(4, 'squeek', ['cheese', 'root'])\n",
    "s = Snakie(5, 'hiss', (Rodent))\n",
    "s.bite(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not eating <class '__main__.Snakie'>\n"
     ]
    }
   ],
   "source": [
    "s2 = Snakie(12, \"hiss hiss\", (Rodent))\n",
    "s2.bite(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying:\n",
      "    a = Animal(12, \"moo\", [\"grass mostly\"])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    a.hp\n",
      "Expecting:\n",
      "    12\n",
      "ok\n",
      "Trying:\n",
      "    r = Rodent(4, 'squeeeek', ['cheese', 'root'])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    s = Snakie(5, 'hiss', (Rodent))\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    s.bite(r)\n",
      "Expecting:\n",
      "    squeeeek\n",
      "ok\n",
      "Trying:\n",
      "    r2 = Rodent(4, 'squeak squeak', ['nuts'])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    r2.hp\n",
      "Expecting:\n",
      "    4\n",
      "ok\n",
      "Trying:\n",
      "    a = Animal(12, \"moo\", [\"grass mostly\"])\n",
      "Expecting nothing\n",
      "ok\n",
      "Trying:\n",
      "    s.bite(a)\n",
      "Expecting:\n",
      "    Not eating <class '__main__.Animal'>\n",
      "ok\n",
      "Trying:\n",
      "    print(average([20, 30, 70]))\n",
      "Expecting:\n",
      "    40.0\n",
      "ok\n",
      "9 items had no tests:\n",
      "    __main__\n",
      "    __main__.Animal.__init__\n",
      "    __main__.Animal.damage\n",
      "    __main__.Rodent\n",
      "    __main__.Rodent.__init__\n",
      "    __main__.Snakie\n",
      "    __main__.Snakie.__init__\n",
      "    __main__._43\n",
      "    __main__._43.__init__\n",
      "3 items passed all tests:\n",
      "   2 tests in __main__.Animal\n",
      "   7 tests in __main__.Snakie.bite\n",
      "   1 tests in __main__.average\n",
      "10 tests in 12 items.\n",
      "10 passed and 0 failed.\n",
      "Test passed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=0, attempted=10)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doctest.testmod(verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
